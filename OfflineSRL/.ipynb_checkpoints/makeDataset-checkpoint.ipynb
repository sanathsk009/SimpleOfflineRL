{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a0a76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MDPDataset.old_dataset import *\n",
    "from MDP.old_MDP import MDP\n",
    "from MDP.ChainBandit import ChainBanditMDP\n",
    "from MDP.ChainBanditState import ChainBanditState\n",
    "from BPolicy.ChainBanditPolicy import ChainBanditPolicy\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e701cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 3\n",
    "mdp = ChainBanditMDP(num_states = horizon)\n",
    "policy = ChainBanditPolicy(mdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "640c7302",
   "metadata": {},
   "outputs": [],
   "source": [
    "neps = 50\n",
    "observations = []\n",
    "actions = []\n",
    "rewards = []\n",
    "terminals = []\n",
    "for eps in range(neps):\n",
    "    for timestep in range(horizon+1):\n",
    "        # Get state.\n",
    "        # Add state to list.\n",
    "        cur_state = copy.deepcopy(mdp.cur_state)\n",
    "        observations.append(copy.deepcopy(cur_state.num_list))\n",
    "\n",
    "        # Get action\n",
    "        # Add action to list\n",
    "        cur_action = policy._get_action(state = cur_state)\n",
    "        actions.append(copy.deepcopy(cur_action))\n",
    "\n",
    "        # Execute action\n",
    "        reward, next_state = mdp.execute_agent_action(cur_action)\n",
    "        # Add reward\n",
    "        rewards.append(copy.deepcopy(reward))\n",
    "        \n",
    "        terminals.append(0)\n",
    "    mdp.reset()\n",
    "    terminals[-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b48f3565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "observations = np.array(observations)\n",
    "actions = np.array(actions)\n",
    "rewards = np.array(rewards)\n",
    "terminals = np.array(terminals)\n",
    "\n",
    "dataset = MDPDataset(\n",
    "    observations=observations,\n",
    "    actions=actions,\n",
    "    rewards=rewards,\n",
    "    terminals=terminals,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7107ec8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  0]\n",
      " [ 2  0]\n",
      " [ 3  1]\n",
      " [-1 -1]]\n",
      "[[ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 0]]\n",
      "[0.  0.5 0.  0. ]\n"
     ]
    }
   ],
   "source": [
    "# first episode\n",
    "episode = dataset.episodes[20]\n",
    "\n",
    "# access to episode data\n",
    "print(episode.observations)\n",
    "print(episode.actions)\n",
    "print(episode.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff19db0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "[1]\n",
      "0.0\n",
      "[2 0]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# first transition\n",
    "transition = episode.transitions[0]\n",
    "\n",
    "# access to tuple\n",
    "print(transition.observation)\n",
    "print(transition.action)\n",
    "print(transition.reward)\n",
    "print(transition.next_observation)\n",
    "print(transition.terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8921ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode.transitions[2].next_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "181f58b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from OfflineLearners.offlineLearners import VI, PVI, SPVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31032c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi = VI(name = \"vi\", states = observations, actions = policy.actions, epLen = horizon)\n",
    "vi.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ec71031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vi rewards:  0.00175\n"
     ]
    }
   ],
   "source": [
    "mdp = ChainBanditMDP(num_states = horizon)\n",
    "neps = 10000\n",
    "viobservations = []\n",
    "viactions = []\n",
    "virewards = []\n",
    "viterminals = []\n",
    "for eps in range(neps):\n",
    "    for timestep in range(horizon):\n",
    "        # Get state.\n",
    "        # Add state to list.\n",
    "        cur_state = copy.deepcopy(mdp.cur_state)\n",
    "        viobservations.append(copy.deepcopy(cur_state.num_list))\n",
    "\n",
    "        # Get action\n",
    "        # Add action to list\n",
    "        cur_action = vi.act(copy.deepcopy(cur_state.num_list), timestep)\n",
    "        viactions.append(copy.deepcopy(cur_action))\n",
    "\n",
    "        # Execute action\n",
    "        reward, next_state = mdp.execute_agent_action(cur_action)\n",
    "        # Add reward\n",
    "        virewards.append(copy.deepcopy(reward))\n",
    "        \n",
    "        viterminals.append(0)\n",
    "    mdp.reset()\n",
    "    viterminals[-1] = 1\n",
    "print(\"vi rewards: \",np.sum(np.array(rewards))/neps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15d3395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvi = PVI(name = \"pvi\", states = observations, actions = policy.actions, epLen = horizon)\n",
    "pvi.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f18afc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pvi rewards:  0.293\n"
     ]
    }
   ],
   "source": [
    "mdp = ChainBanditMDP(num_states = horizon)\n",
    "neps = 10000\n",
    "pviobservations = []\n",
    "pviactions = []\n",
    "pvirewards = []\n",
    "pviterminals = []\n",
    "for eps in range(neps):\n",
    "    for timestep in range(horizon):\n",
    "        # Get state.\n",
    "        # Add state to list.\n",
    "        cur_state = copy.deepcopy(mdp.cur_state)\n",
    "        pviobservations.append(copy.deepcopy(cur_state.num_list))\n",
    "\n",
    "        # Get action\n",
    "        # Add action to list\n",
    "        cur_action = vi.act(copy.deepcopy(cur_state.num_list), timestep)\n",
    "        pviactions.append(copy.deepcopy(cur_action))\n",
    "\n",
    "        # Execute action\n",
    "        reward, next_state = mdp.execute_agent_action(cur_action)\n",
    "        # Add reward\n",
    "        pvirewards.append(copy.deepcopy(reward))\n",
    "        \n",
    "        pviterminals.append(0)\n",
    "    mdp.reset()\n",
    "    pviterminals[-1] = 1\n",
    "print(\"pvi rewards: \",np.sum(np.array(pvirewards))/neps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c69eb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({(0, 2): array([0., 0., 0.], dtype=float32), (1, 2): array([0., 0., 0.], dtype=float32), (2, 2): array([0., 0., 0.], dtype=float32), (3, 2): array([0., 0., 0.], dtype=float32), (4, 2): array([0., 0., 0.], dtype=float32), (5, 2): array([0., 0., 0.], dtype=float32), (6, 2): array([0., 0., 0.], dtype=float32), (0, 1): array([0., 0., 0.], dtype=float32), (1, 1): array([0., 0., 0.], dtype=float32), (2, 1): array([0., 0., 0.], dtype=float32), (3, 1): array([0., 0., 0.], dtype=float32), (4, 1): array([0., 0., 0.], dtype=float32), (5, 1): array([0., 0., 0.], dtype=float32), (6, 1): array([0., 0., 0.], dtype=float32), (0, 0): array([0., 0., 0.], dtype=float32), (1, 0): array([0., 0., 0.], dtype=float32), (2, 0): array([0., 0., 0.], dtype=float32), (3, 0): array([0., 0., 0.], dtype=float32), (4, 0): array([0., 0., 0.], dtype=float32), (5, 0): array([0., 0., 0.], dtype=float32), (6, 0): array([0., 0., 0.], dtype=float32)}, {3: array([0., 0., 0., 0., 0., 0., 0.], dtype=float32), 2: array([0., 0., 0., 0., 0., 0., 0.], dtype=float32), 1: array([0., 0., 0., 0., 0., 0., 0.], dtype=float32), 0: array([0., 0., 0., 0., 0., 0., 0.], dtype=float32)})\n"
     ]
    }
   ],
   "source": [
    "spvi = SPVI(name = \"pvi\", states = observations, actions = policy.actions, epLen = horizon, bpolicy = policy)\n",
    "spvi.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cb65a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spvi rewards:  0.29025\n"
     ]
    }
   ],
   "source": [
    "mdp = ChainBanditMDP(num_states = horizon)\n",
    "neps = 10000\n",
    "spviobservations = []\n",
    "spviactions = []\n",
    "spvirewards = []\n",
    "spviterminals = []\n",
    "for eps in range(neps):\n",
    "    for timestep in range(horizon):\n",
    "        # Get state.\n",
    "        # Add state to list.\n",
    "        cur_state = copy.deepcopy(mdp.cur_state)\n",
    "        spviobservations.append(copy.deepcopy(cur_state.num_list))\n",
    "\n",
    "        # Get action\n",
    "        # Add action to list\n",
    "        cur_action = vi.act(copy.deepcopy(cur_state.num_list), timestep)\n",
    "        spviactions.append(copy.deepcopy(cur_action))\n",
    "\n",
    "        # Execute action\n",
    "        reward, next_state = mdp.execute_agent_action(cur_action)\n",
    "        # Add reward\n",
    "        spvirewards.append(copy.deepcopy(reward))\n",
    "        \n",
    "        spviterminals.append(0)\n",
    "    mdp.reset()\n",
    "    spviterminals[-1] = 1\n",
    "print(\"spvi rewards: \",np.sum(np.array(spvirewards))/neps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8882cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f36aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
